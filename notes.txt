
The Big FAQ (part 8) can be revisted if at any time I get stuck for easy solutions to common problems

Course Roadmap:
  Getting Requirements ✓
  Docker Install ✓
  Container Basics ✓
  Image Basics ✓
  Docker Networking ✓
  Docker Volumes ✓
  Docker Compose ✓
  Orchestration ✓
  Docker Swarm ✓
  Kubernetes
  Swarm vs. K8s
  Student Q&A
  File Reviews

  References and Documentation all throughout
    Github:
    - Course Github Repo - https://github.com/bretfisher/udemy-docker-mastery
    - Github Basics and Docs - https://docs.github.com/en/get-started/quickstart/set-up-git
    - Github Workflow - https://githubflow.github.io/
    - - Gitflow on Docs - https://docs.github.com/en/get-started/quickstart/github-flow
    Docker:
    - Docker Official Images Library - https://github.com/docker-library/official-images/tree/master/library
    - Storage Drivers Overview - https://docs.docker.com/storage/storagedriver/
    - Data Storage Overview - https://docs.docker.com/storage/
    - Configuring a (non-default) Registry - https://docs.docker.com/registry/configuration/
    - Registry Garbage Colleciton - https://docs.docker.com/registry/garbage-collection/
    - Mirroring DockerHub - https://docs.docker.com/registry/recipes/mirror/
    Docker-Compose:
    - Docker Official Documentation for Docker-Compose - https://docs.docker.com/compose/compose-file/
    - YAML official site - https://yaml.org/
    - YAML formatting scribnotes - https://yaml.org/refcard.html
    - Multiple Compose files - https://docs.docker.com/compose/extends/#multiple-compose-files
    - Compose in production - https://docs.docker.com/compose/production/
    - Secrets in Compose - https://docs.docker.com/compose/compose-file/#secrets-configuration-reference
    Swarm:
    - Docker Official Documentation for swarms - https://docs.docker.com/engine/swarm/services/
    - Swarm Routing Mesh - https://docs.docker.com/engine/swarm/ingress/
    - Secrets in Swarm - https://docs.docker.com/engine/swarm/secrets/
    - Service Update - https://docs.docker.com/engine/reference/commandline/service_update/
    HEALTHCHECK:
    - Healthcheck in Dockerfile - https://docs.docker.com/engine/reference/builder/#healthcheck
    - Healthcheck in Compose - https://docs.docker.com/compose/compose-file/#healthcheck
    Kubernetes:
    - Kubernetes Home - https://kubernetes.io/
    - - Certified Kubernetes Distributors - https://kubernetes.io/partners/#conformance
    - Kubernetes Components - https://kubernetes.io/docs/concepts/overview/components/#master-components
    - Kubernetes Cheat Sheet - https://cheatography.com/gauravpandey44/cheat-sheets/kubernetes-k8s/
    - Kubectl Cheat Sheet - https://kubernetes.io/docs/reference/kubectl/cheatsheet/
    - Kubectl for Docker users - https://kubernetes.io/docs/reference/kubectl/docker-cli-to-kubectl/
    - Service - https://kubernetes.io/docs/concepts/services-networking/service/
    - - Using Services (tutorial) - https://kubernetes.io/docs/tutorials/kubernetes-basics/expose/expose-intro/
    - Node Port - https://kubernetes.io/docs/concepts/services-networking/service/#nodeport
    - K8s DNS spec - https://github.com/kubernetes/dns/blob/master/docs/specification.md 
    - Core DNS for K8s - https://www.coredns.io/plugins/kubernetes/
    - Kubectl Usage Conventions - https://kubernetes.io/docs/reference/kubectl/conventions/
    - - Kubectl Usage Best Practices - https://kubernetes.io/docs/reference/kubectl/conventions/#best-practices
    - Kubernetes Object Management - https://kubernetes.io/docs/concepts/overview/working-with-objects/object-management/
    - - K8s Obj Management using Imperative Commands - https://kubernetes.io/docs/tasks/manage-kubernetes-objects/imperative-command/
    - - Imperative Management using Config Files - https://kubernetes.io/docs/tasks/manage-kubernetes-objects/imperative-config/
    - - Declarative Management using Config Files - https://kubernetes.io/docs/tasks/manage-kubernetes-objects/declarative-config/
    - - Understanding Kubernetes Objects - https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/
    - Kubernetes API Reference - https://kubernetes.io/docs/reference/#api-reference
    - API Server dry-run - https://kubernetes.io/blog/2019/01/14/apiserver-dry-run-and-kubectl-diff/
    - Labels - https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors
    - - https://vsupalov.com/kubernetes-labels-annotations-difference/
    - - https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/
    - Assigning Pods to Nodes - https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
    - Taints and Tolerations - https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
    - K8s Volumes - https://kubernetes.io/docs/concepts/storage/volumes/
    - - Stateful Sets - https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/
    - - Persistent Volumes - https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/
    - Ingress - https://kubernetes.io/docs/concepts/services-networking/ingress/
    - - Ingress Controllers - https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/
    - Custom Resources - https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/
    - - Operator Pattern - https://kubernetes.io/docs/concepts/extend-kubernetes/operator/
    - - - Operator Hub - https://operatorhub.io/
    - - - Awesome Operators List (obsoleted for above) https://github.com/operator-framework/awesome-operators
    Articles:
    - Methodology for building software-as-a-service apps - https://12factor.net/
    - Swarm vs Compose, BFisher AMA - https://github.com/BretFisher/ama/discussions/146
    - History of Kubernetes - https://en.wikipedia.org/wiki/Kubernetes
    - The Comprehensive Dev-Ops Core - https://itrevolution.com/product/the-devops-handbook-second-edition/
    Resources:
    - Static Site Generator - https://jekyllrb.com/
    - Tutorials and Practice for Docker - https://training.play-with-docker.com/
    - K8s Labs in Browser - https://killercoda.com/
    - Curated List of Docker resources and projects - https://github.com/veggiemonk/awesome-docker#registry
    - Cheat Sheet Generator (with community sharing) - https://cheatography.com/

Why Docker?:
  Isolation
    - old servers kept apps all over the place spread across machines, causing regular problems, but then came...
    - Virtual Machines: VM's which allowed servers to be spun up on demand
      - accessability became a problem as even simple programs contained uneccesary chaff
  Environment
    - programming for multiple environments bleeds complexity.
    - the "Matrix from Hell" represents every part of your app interacting with every user.
    - Containers: an abstract, representing the "MfH"
  Speed (of change)
    - discussing the speed of business, not anything to do with hardware or software
    - Containers are the next step in computing that allow faster; development, building, testing, and deploying

The 3 step Docker workflow:
  build
    - Dockerfile: OCI image standard
    - universal package manager
    Image layers
      python bins+libs
      flask
      app
  ship
    - Docker Registry: OCI distribution spec
    - universal app distribution
    - Built image has a unique SHA hash, this allows it to be shared
      push image (docker push)
      pull image (docker pull)
  run
    runs Docker to pull an image
    - Linux/Win Server: self contained machine
    - IMAGE:
      creates and runs container(s) containing your app
      allows mass hosting of the same page.

Running Containers:
  3 major ways to run containers
    - Locally: (Docker Desktop, RD)
    - Server: (Docker Engine, K8s)
    - PaaS: (Cloud Run, Fargate)

What is an Image?
  Quick definition:"The application binaries and dependencies for your app and the metadata on how to run it":
  Official definition:"An Image is an ordered collection of root filesystem changes and 
      the corresponding execution parameters for use witin a container runtime.":
  Importantly, an image is only the kernel modules, without the kernel. It is NOT an OS, which makes it much lighter than VMs
  Dockerhub:
    - basically Github for Docker images
    - best practice for production includes pulling exact versions of an image
    - Alpine images are typically smaller than their counterparts
  Layers:
    - Images are built on a layer system
    - you never store the same data more than once
    - each time your image uses the same layer as another image, it's using the actual same layer
  (docker inspect *image*) gives a json file containing all the metadata for the image
  Image, Tag and Push:
    {docker image tag *--help*}
    - tags point to a specific image version
    - when you pull IMAGE:latest or IMAGE:mainline you are pulling a specific version of IMAGE
    {docker image tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]}
    - if you don't specify a tag it will default to "latest"
    - you can tag pretty much anything as pretty much anything, follow conventions please

Persistent Data
  Containers are built to be disposable and easy to change, swap, and redeploy.
  This can cause issues when we want data to stick around between deployments.
  The two solutions Docker makes use of are [Volumes] and [Bind Mounts]
    - Volumes: make a special location outside of the container UFS
    - Bind Mounts: Link the containers path to a host path
  Volumes:
    - VOLUME is a command in Dockerfile, the choosen path will reference a location outside the container created
    (VOLUME [/PATH])
    - when a container is removed the volume will remain and the data in it is safe
    - volumes can be named for human readability
    {docker container run [OPTIONS] IMAGE [-v NAME:/PATH] [ARG]}
  Bind Mounting:
    - Bind Mounting is when you map a host file or directory to a container file or directory
    - this is effectively just having two seperate pointers for the same location
    - Can't use in Dockerfile, must be set up at container run
    {... run [-v /HOST_DIRECTORY:/CONTAINER_PATH]}
    - in a folder which contains your index.html
    {docker container run -d --name IMAGE_NAME -p PORT_MAP [-v $(pwd):/CONTAINER_HTML_PATH] IMAGE}
    - the example used is
    {docker container run -d --name nginx -p 80:80 -v $(pwd):/usr/share/nginx/html nginx}
    - this allows you to edit your code on a host machine and have it apply to your containers without needing to work inside them

Docker Compose
  Containers are typically self-contained and designed for a single or small number of tasks
  Docker Compose makes it easier to manipulate data and processes through many containers working in tandem
  Docker Compose is comprised of two major parts, [YAML File] and [docker-compose CLI tool]
    - YAML-formatted files describe our solutions for a number of tasks relating to our container groups and display heiarchy
    - docker-compose CLI is used for manual manipulation of YAML parameters
  YAML:
    - containers
    - networks
    - volumes
  docker-compose:
    - development
    - test automation
  docker-compose is the default filename, but any filename can be used if you instead call docker-compose -f 'filename'
  docker-compose has been integrated with docker desktop, (docker compose up) is now a better version of (docker-compose up)

Swarm Mode
  ? How do we automate container lifecycle ?
  ? How can we easily scale directionally ?
  ? How can we ensure our containers restart on failure ?
  ? How can we replace containers without downtime ?
  ? How can we control and track where containers start ?
  ? How can we create cross-node virtual networks ?
  ? How can we ensure only secure servers run our containers ?
  ? How can we store secrets, keys, passwords and make sure only the correct container gets them ?
  ! INTRODUCING SWARM MODE !
  - Swarm Mode is a server clustering solution built into Docker
  - unrelated to Swarm "classic" for pre-1.12 versions
  Swarm allows the creation of a 'service' which can create and manage 'workers'.
    this allows a 'manager' to offload tasks to available 'worker' nodes and reduce individual workloads
  Swarm is disabled by default, once enabled you get new commands such as;
    (docker swarm), (docker node), (docker service), (docker stack), and (docker secret)
    To enable: use (docker swarm init). This creates a single-node swarm by default
  - Once swarm is enabled 'service' replaces 'compose' in general command use
    {docker service create alpine ping 8.8.8.8} #ping 8.8.8.8 is just to give image something to do
    {docker service ls}
    {docker service update [IMAGE_ID] --replicas 3} #creates copies of selected image
    {docker container ls} #now shows 3 identical containers
    - if an individual container fails then service will automatically recreate it.
    {docker service rm [IMAGE_NAME]} #required to actually remove containers
  Spinning up VM's to play with:
    Docker-Machine has been depreciated, use Multipass as a better option for managing multiple local VM's

Service (Swarm) Updates
  Swarm updates through a rolling replacement of tasks&containers in a service
    - this helps massively in limiting downtime (though doesn't 'prevent' downtime)
  For most updates your containers will all be replaced, though there are many cli options to control the operation
  There are rollback, healthcare, & scale options
  there is no (service update) command, rather you will deploy and if a service exists it will update the current service
  Some examples for updates include;
    - updating an image to a newer deployment
    - adding an environment variable such as removing a port
    - changing replica numbers for multiple services
  once again, updating is just an edit of the YAML file then {docker stack deploy -c file.yml <stackname>}
HEALTHCHECK was added in 1.12, supported in Dockerfile, Compose YAML, docker run, & Swarm Services
  - it expects exit 0 (OK) or exit 1 (Error)
  - there are three container states: starting, healthy, & unhealthy
  Healthcheck status shows up in {docker container ls}
  last 5 healthchecks can be seen with {docker container inspect}
  Docker run does nothing with these, but services will replace tasks that fail and service updates will wait for confirmation
  Options include;
•|interval=DURATION (default: 30s, how often (in seconds) the health will be checked)
•|timeout=DURATION (default: 30s, how long (in seconds) before an attempt fails through timeout)
•|start-period=DURATION (default: 0s, how long (in seconds) before an attempt will be started (slow booting apps))
•|retries=N (default: 3, how many attempts can be made to get a healhty result)
  {HEALTHCHECK curl -f http://localhost/ || false}
  {HEALTHCHECK --timeout=2s --interval=3s --retries=3 CMD curl -f http://localhost || exit 1} (options require CMD)
  running a static site? Just test default URL
  {FROM nginx:1.13
  HEALTHCHECK --interval=30s --timeout=3s CMD curl -f http://localhost/ || exit 1}

Container Registries
  - registries are a required part of a container plan
  Docker Hub: Digging Deeper
    - while Docker Hub is the most popular image registry, it isn't the only one.
    - Docker Hub is really Docker Registry with some simple Image Building tools built in.
    the "Create Automated Build" option allows you to auto-build a Docker Repository from Github and have it auto-update
    This is the prefered way to build a repository if you are building through a Github project
  Docker Registry
    - Docker Registry is a private image registry for your network
    - the default in private container registries
    - less featured than Docker Hub or others with no web UI but being simple is still useful
    Now that we are working in registries, it's important to pay attention to garbage collection.
  Create A Registry
    - runs default port 5000, re-tag an existing image and push to your registry
    - Docker won't talk to a registry without HTTPS, "secure by default"
    - there's an exception for localhost (127.0.0.0/8)
    {docker container run -d -p 5000:5000 --name regis registry} the image is named registry
    {docker pull hello-world} tiny, basic image. for example purposes
    {docker tag hello-world 127.0.0.1:5000/hello-world} make my own official image at the root of my registry
    on {docker image ls} you will now see two repositories using the same image.
    {docker push 127.0.0.1:5000/hello-world} will effectively 'publish' the image onto your local root
    {docker image remove hello-world}{docker image remove 127.0.0.1:5000/hello-world} remove images from machine
    now {docker pull 127.0.0.1:5000/hello-world} will pull that same image, it's effectively published into that repository
    To use a volume, let's first clean up our mess {docker container kill regis}{docker container rm regis} then;
    {docker container run -d -p 5000:5000 --name regis -v $(pwd)/registry-data:/var/lib/registry registry}
    {docker push 127.0.0.1:5000/hello-world} and now our (127.0.0.1:5000/hello-world) is stored in our volume

Kubernetes
  What is K8s? 
  - A container orchestrator. Originally released by Google, now an opensource project.
  - It's a set of APIs that run on top of Docker(usually) and provides API/CLI management options
  - Many cloud services provide a version of Kubernetes for you.
  Why K8s?
  - It provides Container Orchestration, which is the 'next step' in application development and deployment
  - There are other Orchestrators but for the purpose of hybrid/generalized, Swarm and Kubernetes are the leaders
  K8s or Swarm?
    Swarm: easier to deploy/manage
    - Comes with docker, single vendor container platform. 
    - 80/20 rule, has 20% features that solves 80% of cases.
    - Runs anywhere that docker runs (so basically anywhere).
    - Secure by default, and easier to troubleshoot.
    Kubernetes: has more features/flexibility as well as wider adoption and support
    - Clouds and vendors will deploy/manage K8s for you
    - Infrastructor vendors are making their own 'official' distributions
    - Widest adoption and community
    - Flexible, covers the widest set of use cases
    - "No one ever got fired for buying IBM" - It's the trendy option that luddite bosses may buy.
  Basic Terminology:
    Kubernetes: The orchestration system as a whole
      - K8s, "k-eights", or Kube for short
    Kubectl: CLI to configure Kubernetes and manage apps
      - Using "cube control" official pronunciation
    Node: a single server in the Kubernetes cluster
    Kubelet: Kubernetes agent running on nodes
    Pod: one or more containers running together on one Node
      - basic unit of deployment, containers are always in pods
      - K8s can't directly create a container, instead you make a pod that creates the container inside
    Controller: for creating/updating pods and other objects
    Control Plane: Set of containers that manage the cluster
      - this inlcudes the API server, scheduler, controller manage, etcd, and more
      - sometimes called master
    Service: network endpoint to connect to a pod
    Namespace: Filtered group of objects in cluster
      - just a filter, not a security feature
  Kubectl CLI: #Imperative Kubernetes
    The Three Primary kubectl CLI commands to create a pod:
      {kubectl run} #single pod per command since 1.18, for troubleshooting mainly
        - {kubectl run NAME --image IMAGE} - unlike Docker, NAME is required
      {kubectl create} #create some resources via CLI or YAML
        - {kubectl create deploy(ment) NAME --image IMAGE} - deployment is a different resource than pod
      {kubectl apply} #create/update anything via YAML
    Get: {kubectl get OPTION} #your general purpose information display
      - {kubectl get pods} for example will display your pods Name/Readystate/Status/Restarts/Age
      - {kubectl get all} will display all K8s processes running (pods/cluster/deployment/replicaset)
    Cleanup: {kubectl delete OPTION} #delete your stuff, clean workspaces mean clean(er) code
      - {kubectl delete pod/NAME} to remove a specific pod
      - {kubectl delete deploy(ment)/NAME} to remove a deployment environment
      - {kubectl delete service/NAME} to remove a service
      - delete can be stacked {kubectl delete deploy/NAME service/NAME service/NAME ...etc...}
    Scale: {kubectl scale deploy(ment) NAME --replicas COUNT}
      - {kubectl scale deploy/NAME} and {kubectl scale deploy NAME} are the same
      - deploy = deployment = deployments
      - "--replicas COUNT" sets desired replica amount to COUNT. declarative
    Logs: {kubectl logs deployment/NAME}
      - "--follow" wait for new data to be logged
      - "--tail 1" show only last line to avoid massive log dump
      {kubectl logs -l run=TAG} #NAME is auto-tagged on pod creation
    Describe: {kubectl describe POD/NAME} #gives detailed information on a single pod
      - use {kubectl get pods} to get the name of your pod
    Expose: {kubectl expose deploy(ment) NAME --port PORT} # creates a service(network connection point) for existing pods
      - ClusterIP(default): single, internal virtual ip allocated. Only reachable from within cluster.
      - NodePort: high port allocated on each node. Port is open on every node's IP.
        {kubectl expose deploy(ment) NAME --port PORT --name NEWNAME --type NodePort}
      - LoadBalancer: controls a LB endpoint external to the cluster. for traffic coming in from external source.
        {kubectl expose deploy(ment) NAME --port PORT --name NEWNAME --type LoadBalancer}
      Cluster-->NodePort-->LoadBalancer. Each stacks on the last. A NodePort type service will still have a Cluster-IP
      - ExternalName: adds CNAME DNS record to CoreDNS only. services in cluster can resolve different endpoints.
      - Ingress: for HTTP traffic specificaly
  Kubernetes Services DNS
    CoreDNS: default since 1.11
      - we've been using hostnames {curl <hostname>} but that doesn't work outside the same Namespace {kubectl get namespaces}
      - default format for service DNS is {curl <hostname>.<namespace>.svc.cluster.local}
  Run, Create, and Expose Generators: 
    - These commands use helper templates called "generators"
    - Every resource in K8s has a specification or "spec"
    - You can output those templates with --dry-run -o yaml {kubectl create deploy/sample --image nginx --dry-run -o yaml}
    - Generators are "opinionated defaults"
  Imperative vs. Declarative: 
      - "I'd like a cup of apple cider"
    Imperative: Focus is on •how• a program operates
      - Boil a quart of water, scoop 1 tablespoon of apple cider powder mix, pour over boiling water, ..etc..
    Declarative: Focus is on •what• a program should accomplish
      - "Hey Mom(engine), I'd like a cup of apple cider" (engine works through the steps and is only finished when I have a cup)
    Kubernetes Imperative: {kubectl run},{kubectl create deploy},{kubectl update}
      - We start with a state we know (no deployment exists)
      - We ask kubectl run to create a deployment
      - ...etc...
      Imperative is easier when you know the state, is easier to get started with, and is easier for humans at the CLI
      Imperative, however, is NOT easy to automate
    Kubernetes Declarative: {kubectl apply -f my-resources.yaml}
      - We don't know the current state
      - We only know what we want the end result to be (yaml contents)
        Same command each time
        Resources can be all in a file, or many files #apply a whole dir
      Declarative requires understanding the YAML keys and values, more work for initial results
      Declarative, however, is by FAR the easiest way to automate
  Three Management Approaches:
    Imperative Commands:
      - run, expose, scale, edit, create deploy. 
      - best for dev/learning/personal projects. 
      - easy to learn, hard to manage
    Imperative Objects: 
      - create -f file.yml, replace -f file.yml, delete.
      - good for production of small environments. Single file per command
      - stores your changes in git-based yaml files.
      - hard to automate.
    Declarative Objects: #lotsa reading in resources above
      - apply -f file.yml OR dir\, diff
      - best for production, easiest to automate
      - harder to understand and predict changes
    MOST IMPORTANT RULE:
      Pick one, and stick with it. Avoid mixing these three approaches.
      Bret's Recommendations:
      - Learn Imperative CLI for easy control of local and test setups
      - Store YAML in git, git commit each change before you apply.
Moving to Declarative Kubernetes:
  Basic Terminology cont.:
    Manifest: A description of an API object
      - requires [apiVersion:, kind:, metadata:, and spec:]
      - the base required information for a yaml file
      apiVersion: What API version you use for the resource
        - {kubectl api-versions} can get the API versions the cluster supports
      kind: What resource you are going to get
        - {kubectl api-resources} can get a list of resources the cluster supports
        - KIND is used to inform what purpose a resource has.
      metadata: The name of the resource you are going to create
        - only a name is required
        - labels are applied here, used to create key:value pairs that can be filtered or searched for later
      spec: what you are doing, the path and purpose of execution
        - where all the action is at
    Labels: A key:value pair used to identify and sort information
      - included in the metadata:, labels are simple key:value pairs designed for human sensibilities
      - can filter other commands, ie: {kubectl get pods -l app=nginx} or {kubectl apply -f myfile.yaml -l app=nginx}
      - common examples include [tier: frontend, app: api, env: prod, costomer: acme.co, ...etc...]
      - not meant to hold complex or non-id info, that job belongs to 'annotations'
    Label Selectors: the "glue" telling Services and Deployments which pods are theirs
      - many resources use Label Selectors to "link" resource dependencies
      - you'll see these match up in the Service and Deployment YAML [Building your YAML files:] 
        - or app.yaml in /assignments/section-17/k8s-yaml
      - Labels and Selectors are used to control which pods go to which nodes
      - Taints and Tolerations are the blacklist version of Label Selectors' whitelist
  Kubectl CLI cont.: #Declarative Kubernetes
    Apply: {kubectl apply -f METHOD}
      - {kubectl apply -f myfile.yaml} - create/update resources in a file
      - {kubectl apply -f myyaml/} - create/update a whole directory of yaml
      - {kubectl apply -f https://bret.run/pod.yml} - create/update from a URL (don't be a moron, it's a one-line pull and run)
    API: 
      {kubectl api-resources}
        - lists all resources we have available to use in Kubernetes
      {kubectl api-versions}
        - a shorter list of just the api versions we need to worry about
    Explain: {kubectl explain RESOURCE [options]}
      {kubectl explain KIND --recursive} #will display all keys supported in the YAML file
      {kubectl explain KIND.SUB} #gives a more verbose description of more specific subkeys
      {kubectl explain KIND.SUB.SUB} #drills even further into details including LoadBalancer etc.
      - {kubectl explain services.spec.type}
      - spec can have a sub spec of other resources {kubectl explain deployment.spec.template.spec.volumes.nfs.server}
    Dry Run: {kubectl apply -f FILE.yml --dry-run=OPTION} #option can be client or server
      {kubectl apply -f FILE.yml --dry-run=client} #dry-run a create (client side only)
      {kubectl apply -f FILE.yml --dry-run=server} #dry-run a create/update on a server
      {kubectl diff -f app.yml} #see the difference between current yml and what's on the server
  Kubernetes Configuration YAML: (YAML or JSON) #YAML is more human-readable
    - Each file contains one or more manifests
    - Each manifest describes an API object (deployment, job, secret)
    - Each manifest needs four parts (root key:values in the file)
  Building your YAML files:
    •|apiVersion: v1
    •|kind: Service
    •|metadata
    •|  name: app-nginx-service #minimum required is a name
    •|spec:
    •|  type: NodePort
    •|  ports:
    •|    - port: 80
    •|  selector: #for a label, required. Select pods based on match
    •|    app: app-nginx
    •|--- #literal "---", used to seperate manifests in a single yml file
    •|apiVersion: apps/v1
    •|kind: Deployment
    •|metadata:
    •|  name: app-nginx-deployment
    •|spec:
    •|  replicas: 3
    •|  selector:
    •|    matchLabels:
    •|      app: app-nginx
    •|  template:
    •|    metadata:
    •|      labels: #connecting to selector, must sync. Select pods based on match
    •|        app: app-nginx
    •|    spec:
    •|      containers:
    •|        - name: nginx
    •|          image: nginx:1.17.3
    •|          ports:
    •|            - containerPort: 80
Storage In Kubernetes:
  - Storage and stateful workloads are harder in all systems, containers make it both harder and easier
  StatefulSets: is a new resource type, making Pods more sticky.
  Volumes: are tied to the lifecycle of a Pod and all containers in a single Pod can share them.
  PersistentVolumes: are created at the cluster level and outlive a Pod. Multiple Pods can share them.
  CSI(Container Storage Interface) plugins: are the new way to connect to storage.
  Ingress: routes outside connections based on hostname or URL
    - Nginx is popular, but Traefik, HAProxy, F5, Envoy, Istio, ...etc... also exist
    - Implementation is specific to the Controller you choose
  CRD's and The Operator Pattern: 3rd party Resources and Controllers
    - Extends Kubernetes API and CLI
    Operator: automate deployment and management of complex apps
      - Databases, monitoring tools, backups, and custom ingresses
  Higher Deployment Abstractions:
    kubectl commands just talk to the Kubernetes API
    Kubernetes has limited built-in templating, versioning, tracking, and management of you apps
    - Many people design their own templates and have their own opinion on what clean code should look like
    - "Helm" is the most popular, "Compose on Kubernetes" comes with Docker Desktop, there are well over 60 other options
    Most deployment tools are only there to Template your YAML
    - "Helm" was the first winner in this space but can be complex
    - Kustomize is the Official Kubernetes version which works out-of-the-box since 1.14
    - docker app and compose-on-kubernetes are the Docker version
  Kubernetes Dashboard: default GUI for "upstream" Kubernetes
    Some distributions have their own GUI (Rancher, Docker Ent, OpenShift)
    - Clouds don't have it by default
    Let's you review resources and upload YAML
    !NOT Secure by Default!
  Namespaces and Context
    Namespaces limit scope, aka "virtual clusters"
    not related to Docker/Linux namespaces
    not needed in small clusters
    there are some built-in, to hide system stuff from kubectl "users"
    {kubectl get namespaces} #will show what namespaces are in use
    {kubectl get all --all-namespaces} #will get all, from every namespace
    Context: changes kubectl cluster and namespace. can be sumarized in three parts
      - Cluster #what cluster you are looking at
      - Auth/User #who you are looking at the cluster as
      - Namespace #what namespace within a cluster you are looking at
      {kubectl config get-contents} #shows context info
      {kubectl config set*} #changes your context paramaters

Automated CLI Workflows:
  CI/CD = Continuous Integration and Continuous Deployment(Delivery)
  The Pull Request: the github workflow
    A standard repository update system where you request for your current github branch to be pushed to the main branch
      First, create a branch of a github repo to work on.
      Second, open a pull request, getting feedback from other collaborators.
      Third, get approval and merge PR into the main branch.
    What do we need to automate?
      First, open PR
      Second, merge PR
    Why bother with this automation?
      It's the glue that holds Dev-Ops together.
    !ALWAYS LINT!
    Using GitHub Actions:
      - what is GHA? - https://www.youtube.com/watch?v=cP0I9w2coGU
      - learning GHA - https://docs.github.com/en/actions
  Assuming PR Workflow, What needs automation in Docker?
    Basic Docker Build:
    BuildKit Cache:
    Multi-Platform Builds:
    Metadata and Dynamic Builds:
    GitHub Comments:
    CVE Scanning of Images:
    CVE Scan Blocking:
    Unit & Integration Testing:
    Kubernetes Smoke Test:
    (bonus) Job Parallelization for GHA: